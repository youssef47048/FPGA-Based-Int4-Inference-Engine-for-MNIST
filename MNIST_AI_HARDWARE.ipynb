{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCOkUyE_IGgc",
        "outputId": "9396aa26-92fa-4f11-993e-93e09dd7e55b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 6 epochs (bias=False)...\n",
            "Epoch 1/6 complete. Loss: 0.3354\n",
            "Epoch 2/6 complete. Loss: 0.0656\n",
            "Epoch 3/6 complete. Loss: 0.3705\n",
            "Epoch 4/6 complete. Loss: 0.0265\n",
            "Epoch 5/6 complete. Loss: 0.0149\n",
            "Epoch 6/6 complete. Loss: 0.0371\n",
            "\n",
            "--- Calculating Original (Floating-Point) Model Accuracy ---\n",
            "Original Model Accuracy: 97.09%\n",
            "\n",
            "--- Starting Quantization ---\n",
            "Saved w1.mem\n",
            "Saved w2.mem\n",
            "Saved w3.mem\n",
            "Saved input1.mem\n",
            "\n",
            "Expected Label for input.mem: 1\n",
            "\n",
            "--- Golden Reference (Integer Simulation) ---\n",
            "Layer 3 Output (logits): [-17.  32. -17. -16. -13. -23. -15.   8. -10.  -5.]\n",
            "Predicted Digit: 1\n",
            "\n",
            "--- Calculating Quantized Model Accuracy (Hardware Simulation) ---\n",
            "Quantized Model Accuracy: 95.56%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# --- Configuration ---\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 6\n",
        "LEARNING_RATE = 0.001\n",
        "HIDDEN_1 = 64\n",
        "HIDDEN_2 = 32\n",
        "\n",
        "# --- 1. Data Setup ---\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# --- 2. Define the Model (Hardware Optimized) ---\n",
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleMLP, self).__init__()\n",
        "        # bias=False ensures PyTorch learns to work without biases,\n",
        "        # exactly matching our simple Verilog MAC unit.\n",
        "        self.fc1 = nn.Linear(28*28, HIDDEN_1, bias=False)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(HIDDEN_1, HIDDEN_2, bias=False)\n",
        "        self.fc3 = nn.Linear(HIDDEN_2, 10, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleMLP()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# --- 3. Training Loop ---\n",
        "print(f\"Training for {EPOCHS} epochs (bias=False)...\")\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} complete. Loss: {loss.item():.4f}\")\n",
        "# --- 3.1 Model Accuracy\n",
        "print(\"\\n--- Calculating Original (Floating-Point) Model Accuracy ---\")\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Set model to evaluation mode (good practice, though your simple model behaves same as train)\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad(): # Turn off gradient calculation to save memory/speed\n",
        "    for data, target in test_loader:\n",
        "        # Pass the standard floating point data (0.0 to 1.0) through the model\n",
        "        output = model(data)\n",
        "\n",
        "        # Get the index of the max log-probability (the predicted digit)\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "\n",
        "        # Check how many matched the target label\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        total += data.shape[0]\n",
        "\n",
        "accuracy = 100. * correct / total\n",
        "print(f\"Original Model Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "# --- 4. Quantization Helper Functions ---\n",
        "def quantize_tensor(tensor, min_val=-8, max_val=7):\n",
        "    abs_max = torch.max(torch.abs(tensor))\n",
        "    if abs_max == 0: return tensor.int(), 1.0\n",
        "\n",
        "    scale = abs_max / max(abs(min_val), abs(max_val))\n",
        "    tensor_q = torch.round(tensor / scale)\n",
        "    tensor_q = torch.clamp(tensor_q, min_val, max_val)\n",
        "    return tensor_q.int(), scale\n",
        "\n",
        "def to_hex(val, bits=4):\n",
        "    val = int(val)\n",
        "    if val < 0: val = (1 << bits) + val\n",
        "    return f\"{val:0{bits//4}x}\"\n",
        "\n",
        "def save_mem_file(filename, tensor, bits=4):\n",
        "    data_flat = tensor.detach().numpy().flatten()\n",
        "    with open(filename, 'w') as f:\n",
        "        for val in data_flat:\n",
        "            f.write(f\"{to_hex(val, bits)}\\n\")\n",
        "    print(f\"Saved {filename}\")\n",
        "\n",
        "# --- 5. Perform Quantization and Export ---\n",
        "print(\"\\n--- Starting Quantization ---\")\n",
        "\n",
        "# A. Quantize Weights Only (No Biases)\n",
        "w1_q, s1 = quantize_tensor(model.fc1.weight, -8, 7)\n",
        "w2_q, s2 = quantize_tensor(model.fc2.weight, -8, 7)\n",
        "w3_q, s3 = quantize_tensor(model.fc3.weight, -8, 7)\n",
        "\n",
        "# B. Export Weights\n",
        "# Note: We do NOT transpose (.t()) here so Verilog reads memory linearly\n",
        "save_mem_file(\"w1.mem\", w1_q)\n",
        "save_mem_file(\"w2.mem\", w2_q)\n",
        "save_mem_file(\"w3.mem\", w3_q)\n",
        "\n",
        "# C. Export Test Image\n",
        "# Get one image from test set\n",
        "test_img, test_label = test_data[5]\n",
        "img_q = torch.round(test_img * 15).int()\n",
        "save_mem_file(\"input1.mem\", img_q)\n",
        "\n",
        "print(f\"\\nExpected Label for input.mem: {test_label}\")\n",
        "\n",
        "# --- 6. Hardware Golden Reference Check ---\n",
        "# We simulate the hardware math here to know what the FPGA *should* output\n",
        "def hardware_simulate(x, w):\n",
        "    # No bias addition here\n",
        "    res = torch.matmul(x.float(), w.float())\n",
        "    return res\n",
        "\n",
        "# Flatten input\n",
        "x_vec = img_q.flatten().float()\n",
        "\n",
        "# Layer 1\n",
        "# Note: .t() is required for Python math, but not for the .mem file export\n",
        "z1 = torch.matmul(x_vec, w1_q.t().float())\n",
        "a1 = torch.clamp(torch.floor(z1/64), 0, 15)\n",
        "\n",
        "# Layer 2\n",
        "z2 = torch.matmul(a1, w2_q.t().float())\n",
        "a2 = torch.clamp(torch.floor(z2/64), 0, 15)\n",
        "\n",
        "# Layer 3\n",
        "z3 = torch.matmul(a2, w3_q.t().float())\n",
        "\n",
        "print(\"\\n--- Golden Reference (Integer Simulation) ---\")\n",
        "print(\"Layer 3 Output (logits):\", z3.detach().numpy())\n",
        "print(\"Predicted Digit:\", torch.argmax(z3).item())\n",
        "\n",
        "# --- 7. Calculate Full Quantized Accuracy ---\n",
        "print(\"\\n--- Calculating Quantized Model Accuracy (Hardware Simulation) ---\")\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        img_q_batch = torch.round(data * 15).int()\n",
        "        x_batch = img_q_batch.view(-1, 28*28).float()\n",
        "\n",
        "        # Hardware Simulation Loop\n",
        "        # Layer 1\n",
        "        z1 = torch.matmul(x_batch, w1_q.t().float())\n",
        "        z1 = torch.floor(z1 / 64)   # Bit shift right 6\n",
        "        z1 = torch.clamp(z1, 0, 15) # ReLU\n",
        "\n",
        "        # Layer 2\n",
        "        z2 = torch.matmul(z1, w2_q.t().float())\n",
        "        z2 = torch.floor(z2 / 64)\n",
        "        z2 = torch.clamp(z2, 0, 15)\n",
        "\n",
        "        # Layer 3\n",
        "        z3 = torch.matmul(z2, w3_q.t().float())\n",
        "\n",
        "        # Prediction\n",
        "        pred = z3.argmax(dim=1, keepdim=True)\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        total += data.shape[0]\n",
        "\n",
        "print(f\"Quantized Model Accuracy: {100. * correct / total:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change this index to any number (0 to 9999) to pick a different test image\n",
        "TEST_IMAGE_INDEX = 444\n",
        "\n",
        "# Get image and label\n",
        "test_img, test_label = test_data[TEST_IMAGE_INDEX]\n",
        "img_q = torch.round(test_img * 15).int()\n",
        "\n",
        "# Save only the input file\n",
        "save_mem_file(\"input1.mem\", img_q)\n",
        "print(f\"Saved input1.mem for Image Index {TEST_IMAGE_INDEX} (True Label: {test_label})\")\n",
        "\n",
        "# --- Golden Reference Check for this specific image ---\n",
        "x_vec = img_q.flatten().float()\n",
        "\n",
        "# Layer 1\n",
        "z1 = torch.matmul(x_vec, w1_q.t().float())\n",
        "a1 = torch.clamp(torch.floor(z1/64), 0, 15)\n",
        "\n",
        "# Layer 2\n",
        "z2 = torch.matmul(a1, w2_q.t().float())\n",
        "a2 = torch.clamp(torch.floor(z2/64), 0, 15)\n",
        "\n",
        "# Layer 3\n",
        "z3 = torch.matmul(a2, w3_q.t().float())\n",
        "\n",
        "print(\"\\n--- Python Golden Prediction ---\")\n",
        "print(\"Logits:\", z3.detach().numpy())\n",
        "print(\"Predicted Class:\", torch.argmax(z3).item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFPkl1oTrWVS",
        "outputId": "e3794507-f64b-49b6-8ce8-01038651a2b7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved input1.mem\n",
            "Saved input1.mem for Image Index 444 (True Label: 2)\n",
            "\n",
            "--- Python Golden Prediction ---\n",
            "Logits: [-10.   4.  53.  20. -59. -14. -50.  18.  18.  -7.]\n",
            "Predicted Class: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CWuspeeapURX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}